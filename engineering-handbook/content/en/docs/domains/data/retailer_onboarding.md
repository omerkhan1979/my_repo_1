---
title: "Retailer Onboarding"
---

There are still many lingering single-tenant components that the data pipelines rely on along with the lack of detecting
new retailers.
Various components within the data domain need to be updated prior to launch.

## Prerequisites

* Identify the new retailer code such as econo, smu, pinemelon. Be sure to distinguish the client name (Data lake
  reference) from retailer code.
* Identify the GCP project the single tenant components reside in such
  as [tkf-pinemelon-prod](https://console.cloud.google.com/cloudpubsub/topic/list?project=tkf-pinemelon-prod-b72d)

## Data Lake V1 
(A.K.A. Legacy / sub-bq)

[Example PR](https://github.com/takeoff-com/daas-data-lake-sub-dataflow-bigquery/pull/722/commits/5ae46daecdcfa067600d7075237df846981dd56e)

* Add the new retailer directory following the structure of the other clients including a config.yml:
    * Use [pinemelon](https://github.com/takeoff-com/daas-data-lake-sub-dataflow-bigquery/tree/develop/conf/pinemelon)
      for a retailer that is manual only
    * Use [tienda](https://github.com/takeoff-com/daas-data-lake-sub-dataflow-bigquery/tree/develop/conf/tienda) for OSR
      only
    * Use [albertsons](https://github.com/takeoff-com/daas-data-lake-sub-dataflow-bigquery/tree/develop/conf/albertsons)
      for combination
* Copy all the necessary `sources` schema json files to the new retailer directory. `tables` will be auto generated by
  the CI workflow.
* Update
  the [data-completeness-check config](https://github.com/takeoff-com/daas-data-lake-sub-dataflow-bigquery/blob/5ae46daecdcfa067600d7075237df846981dd56e/monitoring/data_completeness_check/src/config.yml)
  with the appropriate table names

## Data Lake V2
(A.K.A. Raw Ingestion / dl-ingest)

[Example PR](https://github.com/takeoff-com/daas-data-lake-ingestion/pull/34/files)

* Review all the pubsub topics in the upstream single tenant project
* Update the mappings in every topic config that contains specific retailer mappings
  in [daas-data-lake-ingestion](https://github.com/takeoff-com/daas-data-lake-ingestion/blob/b7e0981860088c3da559e56b9108727e55dc74b8/infrastructure/production/tables/terragrunt.hcl#L23-L30)

## Data Scrapers (pub-gen)
(A.K.A. pub-gen)

* V2 Secrets ([Example PR](https://github.com/takeoff-com/daas-data-lake-pub-generator-secrets/pull/9))
    * Base64 decode the [shared token](https://github.com/takeoff-com/shared-tokens) for the retailer
    * Decrypt the secrets file
      in [daas-data-lake-pub-generator-secrets](https://github.com/takeoff-com/daas-data-lake-pub-generator-secrets)
      following the README
    * Add the secret as a tom-api configuration
    * Re-encrypt and PR the changes
* Order Picker
  Assignments ([Example PR](https://github.com/takeoff-com/daas-transformer-picker-assignments/pull/21/files)):
    * Update the picker assignments transformer with the new single tenant project
      topic: https://github.com/takeoff-com/daas-transformer-picker-assignments/pull/21/files
* V1 Scrapers ([Example PR](https://github.com/takeoff-com/daas-data-lake-pub-generator/pull/659/files))
    * Secrets:
        * Decrypt the secrets files in [pub-gen](https://github.com/takeoff-com/daas-data-lake-pub-generator) following
          the README
        * Update
          the [tom-api-keys](https://github.com/takeoff-com/daas-data-lake-pub-generator/blob/f564cb6cbbcb66a0d53520556a9359cc984b407a/conf/production/tom_api/tom-api-keys.enc.yml)
          secrets file with the same token extracted in V2 Secrets.
        * Update
          the [database-credentials](https://github.com/takeoff-com/daas-data-lake-pub-generator/blob/f564cb6cbbcb66a0d53520556a9359cc984b407a/conf/production/postgres/database-credentials.enc.yml)
          file with passwords residing in the Data Liquidity 1Password vault. If you lack access to this vault, ensure
          you are a member of team-mario and open an IT ticket to get access.
        * Re-Encrypt and PR the Changes.
    * Scraper Config
        * Add an enabled flag to
          the [scraper config](https://github.com/takeoff-com/daas-data-lake-pub-generator/blob/f564cb6cbbcb66a0d53520556a9359cc984b407a/conf/production/clients.yml)
        * Identify the cloud SQL database residing in the retailer project and identify the project ID, instance name,
          IP address, and region the instance is deployed in.
        * Update
          the [postgres config](https://github.com/takeoff-com/daas-data-lake-pub-generator/blob/f564cb6cbbcb66a0d53520556a9359cc984b407a/conf/production/postgres/config.yml)
          with the retailer db config details.
        * Update each DAGs config with the target pubsub
          topics ([Example](https://github.com/takeoff-com/daas-data-lake-pub-generator/pull/659/files#diff-7fe4f5d444a3b9b8ec1224b1a81b770eaa219e58140dbb73a82cf26a08460d22R20-R21))
        * Add project iam membership in
          terraform. ([Example](https://github.com/takeoff-com/daas-data-lake-pub-generator/blob/f564cb6cbbcb66a0d53520556a9359cc984b407a/terraform/publisher/iam.tf#L188-L193)).

## Data Mart
(A.K.A dw-etl)

[Example PR](https://github.com/takeoff-com/datawarehouse-etl/pull/498/files)

* Add the retailer client code to
  the [clients.yml file](https://github.com/takeoff-com/datawarehouse-etl/blob/master/dbt/clients_datamart/clients.yml).
* Add the retailer code to client ID mapping
  in [dbt_project.yml](https://github.com/takeoff-com/datawarehouse-etl/blob/master/dbt/clients_datamart/dbt_project.yml#L48).
* Add any necessary
  retailer [specific model enabling configuration](https://github.com/takeoff-com/datawarehouse-etl/blob/e41b78afc056a60c7d503ba16157041f4759d228/dbt/clients_datamart/dbt_project.yml#L139-L142)
  based on the template client mentioned before.
* Update
  the [dim_mfc_location model](https://github.com/takeoff-com/datawarehouse-etl/blob/e41b78afc056a60c7d503ba16157041f4759d228/dbt/clients_datamart/models/datamart/dim_mfc_location.sql#L85-L131)
  with retailer specific overrides.
* Enable the clients in all
  relevant [terragrunt configurations](https://github.com/takeoff-com/datawarehouse-etl/blob/e41b78afc056a60c7d503ba16157041f4759d228/terraform/gcp/envs/production/terragrunt.hcl#L17).
* Update
  the [test_manage_cloud_run script](https://github.com/takeoff-com/datawarehouse-etl/blob/e41b78afc056a60c7d503ba16157041f4759d228/tests/test_manage_cloud_run.py#L15)
  or else unit tests will fail.
* Review models for client specific overrides such
  as [fact_productivity](https://github.com/takeoff-com/datawarehouse-etl/blob/e41b78afc056a60c7d503ba16157041f4759d228/dbt/clients_datamart/models/datamart/fact_productivity.sql#L18).

## Looker

* Update
  the [manifest.lkml](https://github.com/takeoff-com/takeoff-looker/blob/ce20dcc21978290d331a504f1c9f547ce1f24e4c/manifest.lkml#L33)
  with the client ID so common models may run.
* Add a model lkml file based on the template
  retailer ([Example](https://github.com/takeoff-com/takeoff-looker/blob/ce20dcc21978290d331a504f1c9f547ce1f24e4c/src/bigquery_models/econo_bq.model.lkml)).
* Add an include dashboards file based on the template
  retailer ([Example](https://github.com/takeoff-com/takeoff-looker/blob/ce20dcc21978290d331a504f1c9f547ce1f24e4c/src/bigquery_models/include_dashboards/econo.view.lkml)).
* Add the client to terraform with a retailer specific timezone mapping. Ask product if needed to identify what this
  should
  be ([Example](https://github.com/takeoff-com/takeoff-looker/blob/ce20dcc21978290d331a504f1c9f547ce1f24e4c/terraform/envs/develop/terragrunt.hcl#L12)).
  Trigger a [terraform deployment](https://github.com/takeoff-com/takeoff-looker/actions/workflows/terraform.yml)
  eventually.

### Looker Admin

* Create a new group `<retailer_code_name>_client_group` under https://takeoff.looker.com/admin/groups
* Under [Looker Roles](https://takeoff.looker.com/admin/roles)
    * update the `all_but_infrastructure_and_client_models` under `Model Sets` with the new retailer model
    * create a new client model set `<retailer_code_name>_client_model_set`
    * Create a new role `<retailer_code_name>_client_role`
        * setup `client_permission_set`
        * include the retailer model set
        * include the retailer client group
* Under [Looker Shared Client Folder](https://takeoff.looker.com/folders/420), create a new folder with the retailer's
  business name